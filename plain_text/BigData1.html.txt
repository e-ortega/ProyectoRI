       IBMÂ®   Mapa del sitio  Marketplace  Cerrar   IBM           In Marketplace Enviar    Mi IBM   Mi IBM    developerWorks    InscrÃ­base    RegÃ­strese  NavegaciÃ³n del sitio    NavegaciÃ³n del sitio Cerrar       Aprenda    Desarrolle    ConÃ©ctese   Marketplace Productos Todos los productos Productos Analytics Cloud Cognitive Watson Customer Engagement Internet of Things (US) Soluciones por Industria Infraestructura de IT Seguridad Watson (US) Social Business Servicios ConsultorÃ­a empresarial Servicios de tecnologÃ­a Financiamiento (US) CapacitaciÃ³n y habilidades (US) Clientes Desarrolladores developerWorks PartnerWorld (US) Empleos Sobre IBM                Aprenda    Desarrolle    ConÃ©ctese           Aprenda Information mgmt                      Contenido IntroducciÃ³n 1. IntroducciÃ³n 2. Â¿De dÃ³nde proviene toda esa informaciÃ³n? 3. Â¿QuÃ© tipos de datos debo explorar? 4. Componentes de una plataforma Big Data 5. Big Data y el campo de investigaciÃ³n 6. Conclusiones 7. Referencias Recursos para Descargar Comentarios       Â¿QuÃ© es Big Data? Todos formamos parte de ese gran crecimiento de datos      Ricardo Barranco Fragoso Publicado en 18-06-2012        Comparta esta pÃ¡gina Digg Facebook Twitter Delicious Linked In Google+             12        1. IntroducciÃ³n El primer cuestionamiento que posiblemente llegue a su mente en este momento es Â¿QuÃ© es Big Data y porquÃ© se ha vuelto tan importante? pues bien, en tÃ©rminos generales podrÃ­amos referirnos como a la tendencia en el avance de la tecnologÃ­a que ha abierto las puertas hacia un nuevo enfoque de entendimiento y toma de decisiones, la cual es utilizada para describir enormes cantidades de datos (estructurados, no estructurados y semi estructurados)  que tomarÃ­a demasiado tiempo y serÃ­a muy costoso cargarlos a un base de datos relacional para su anÃ¡lisis. De tal manera que, el concepto de Big Data aplica para toda aquella informaciÃ³n que no puede ser procesada o analizada utilizando procesos o herramientas tradicionales. Sin embargo, Big Data no se refiere a alguna cantidad en especÃ­fico, ya que es usualmente utilizado cuando se habla en tÃ©rminos de petabytes y exabytes de datos. Entonces Â¿CuÃ¡nto es demasiada informaciÃ³n de manera que sea elegible para ser procesada y analizada utilizando Big Data? Analicemos primeramente en tÃ©rminos de bytes: Gigabyte = 10 9 = 1,000,000,000 Terabyte = 10 12 = 1,000,000,000,000 Petabyte = 10 15 = 1,000,000,000,000,000 Exabyte  = 10 18 = 1,000,000,000,000,000,000 AdemÃ¡s del gran volumen de informaciÃ³n, esta existe en una gran variedad de datos que pueden ser representados de diversas maneras en todo el mundo, por ejemplo de dispositivos mÃ³viles, audio, video, sistemas GPS, incontables sensores digitales en equipos industriales, automÃ³viles, medidores elÃ©ctricos, veletas, anemÃ³metros, etc., los cuales pueden medir y comunicar el posicionamiento, movimiento, vibraciÃ³n, temperatura, humedad y hasta los cambios quÃ­micos que sufre el aire, de tal forma que las aplicaciones que analizan estos datos requieren que la velocidad de respuesta sea lo demasiado rÃ¡pida para lograr obtener la informaciÃ³n correcta en el momento preciso. Estas son las caracterÃ­sticas principales de una oportunidad para Big Data. Es importante entender que las bases de datos convencionales son una parte importante y relevante para  una soluciÃ³n analÃ­tica. De hecho, se vuelve mucho mÃ¡s vital cuando se usa en conjunto con la plataforma de Big Data. Pensemos en nuestras manos izquierda y derecha, cada una ofrece fortalezas individuales para cada tarea en especÃ­fico. Por ejemplo, un beisbolista sabe que una de sus manos es mejor para lanzar la pelota y la otra para atraparla; puede ser que cada mano intente hacer la actividad de la otra, mas sin embargo, el resultado no serÃ¡ el mÃ¡s Ã³ptimo. 2. Â¿De dÃ³nde proviene toda esa informaciÃ³n? Los seres humanos estamos creando y almacenando informaciÃ³n constantemente y cada vez mÃ¡s en cantidades astronÃ³micas. Se podrÃ­a decir que si todos los bits y bytes de datos del Ãºltimo aÃ±o fueran guardados en CD's, se generarÃ­a una gran torre desde la Tierra hasta la Luna y de regreso. Esta contribuciÃ³n a la acumulaciÃ³n masiva de datos la podemos encontrar en diversas industrias, las compaÃ±Ã­as mantienen grandes cantidades de datos transaccionales, reuniendo informaciÃ³n acerca de sus clientes, proveedores, operaciones, etc., de la misma manera sucede con el sector pÃºblico. En muchos paÃ­ses se administran enormes bases de datos que contienen datos de censo de poblaciÃ³n, registros mÃ©dicos, impuestos, etc., y si a todo esto le aÃ±adimos transacciones financieras realizadas en lÃ­nea o por dispositivos mÃ³viles, anÃ¡lisis de redes sociales (en Twitter son cerca de 12 Terabytes de tweets creados diariamente y Facebook almacena alrededor de 100 Petabytes de fotos y videos), ubicaciÃ³n geogrÃ¡fica mediante coordenadas GPS, en otras palabras, todas aquellas actividades que la mayorÃ­a de nosotros realizamos varias veces al dÃ­a con nuestros "smartphones", estamos hablando de que se generan alrededor de 2.5 quintillones de bytes diariamente en el mundo. 1 quintillÃ³n = 10 30 = 1,000,000,000,000,000,000,000,000,000,000 De acuerdo con un estudio realizado por Cisco[1], entre el 2011 y el 2016 la cantidad de trÃ¡fico de datos mÃ³viles crecerÃ¡ a una tasa anual de 78%, asÃ­ como el  nÃºmero de dispositivos mÃ³viles conectados a Internet excederÃ¡ el nÃºmero de habitantes en el planeta. Las naciones unidas proyectan que la poblaciÃ³n mundial alcanzarÃ¡ los 7.5 billones para el 2016 de tal modo que habrÃ¡ cerca de 18.9  billones de dispositivos conectados a la red a escala mundial, esto conllevarÃ­a a que el trÃ¡fico global de datos mÃ³viles alcance 10.8 Exabytes mensuales o 130 Exabytes anuales. Este volumen de trÃ¡fico previsto para 2016 equivale a 33 billones de DVDs anuales o 813 cuatrillones de mensajes de texto. Pero no solamente somos los seres humanos quienes contribuimos a este crecimiento enorme de informaciÃ³n, existe tambiÃ©n la comunicaciÃ³n denominada mÃ¡quina a mÃ¡quina (M2M machine-to-machine) cuyo valor en la creaciÃ³n de grandes cantidades de datos tambiÃ©n es muy importante. Sensores digitales instalados en contenedores para determinar la ruta generada durante una entrega de algÃºn paquete y que esta informaciÃ³n sea enviada a las compaÃ±Ã­as de transportaciÃ³n, sensores en medidores elÃ©ctricos para determinar el consumo de energÃ­a a intervalos regulares para que sea enviada esta informaciÃ³n a las compaÃ±Ã­as del sector energÃ©tico. Se estima que hay mÃ¡s de 30 millones de sensores interconectados en distintos sectores como automotriz, transportaciÃ³n, industrial, servicios, comercial, etc. y se espera que este nÃºmero crezca en un 30% anualmente. 3. Â¿QuÃ© tipos de datos debo explorar? Muchas organizaciones se enfrentan a la pregunta sobre Â¿quÃ© informaciÃ³n es la que se debe analizar?, sin embargo, el cuestionamiento deberÃ­a estar enfocado hacia Â¿quÃ© problema es el que se estÃ¡ tratando de resolver?.[2] Si bien sabemos que existe una amplia variedad de tipos de datos a analizar, una buena clasificaciÃ³n nos ayudarÃ­a a entender mejor su representaciÃ³n, aunque es muy probable que estas categorÃ­as puedan extenderse con el avance tecnolÃ³gico. Figura 1. Tipos de datos de Big
                Data[2] Haga clic para ampliar la imagen 1.- Web and Social Media : Incluye contenido web e informaciÃ³n que es obtenida de las redes sociales como Facebook, Twitter, LinkedIn, etc, blogs. 2.- Machine-to-Machine (M2M) : M2M se refiere a las tecnologÃ­as que permiten conectarse a otros dispositivos. M2M utiliza dispositivos como sensores o medidores que capturan algÃºn evento en particular (velocidad, temperatura, presiÃ³n, variables meteorolÃ³gicas, variables quÃ­micas como la salinidad, etc.) los cuales transmiten a travÃ©s de redes alÃ¡mbricas, inalÃ¡mbricas o hÃ­bridas a otras aplicaciones que traducen estos eventos en informaciÃ³n significativa. 3.- Big Transaction Data : Incluye registros de facturaciÃ³n, en telecomunicaciones registros detallados de las llamadas (CDR), etc. Estos datos transaccionales estÃ¡n disponibles en formatos tanto semiestructurados como no estructurados. 4.- Biometrics : InformaciÃ³n biomÃ©trica en la que se incluye huellas digitales, escaneo de la retina, reconocimiento facial, genÃ©tica, etc. En el Ã¡rea de seguridad e inteligencia, los datos biomÃ©tricos han sido informaciÃ³n importante para las agencias de investigaciÃ³n. 5.- Human Generated : Las personas generamos diversas cantidades de datos como la informaciÃ³n que guarda un call center al establecer una llamada telefÃ³nica, notas de voz, correos electrÃ³nicos, documentos electrÃ³nicos, estudios mÃ©dicos, etc. 4. Componentes de una plataforma Big Data Las organizaciones han atacado esta problemÃ¡tica desde diferentes Ã¡ngulos. Todas esas montaÃ±as de informaciÃ³n han generado un costo potencial al no descubrir el gran valor asociado. Desde luego, el Ã¡ngulo correcto que actualmente tiene el liderazgo en tÃ©rminos de popularidad para analizar enormes cantidades de informaciÃ³n es la plataforma de cÃ³digo abierto Hadoop. Hadoop estÃ¡ inspirado en el proyecto de Google File System(GFS) y en el paradigma de programaciÃ³n MapReduce , el cual consiste en dividir en dos tareas ( mapper â€“ reducer ) para manipular los datos distribuidos a nodos de un clÃºster logrando un alto paralelismo en el procesamiento.[5] Hadoop estÃ¡ compuesto de tres piezas: Hadoop Distributed File System (HDFS), Hadoop MapReduce y Hadoop Common. Hadoop Distributed File System(HDFS) Los datos en el clÃºster de Hadoop son divididos en pequeÃ±as piezas llamadas bloques y distribuidas a travÃ©s del clÃºster; de esta manera, las funciones map y reduce pueden ser ejecutadas en pequeÃ±os subconjuntos y esto provee de la escalabilidad necesaria para el procesamiento de grandes volÃºmenes. La siguiente figura ejemplifica como los bloques de datos son escritos hacia HDFS. Observe que cada bloque es almacenado tres veces y al menos un bloque se almacena en un diferente rack para lograr redundancia. Figura 2. Ejemplo de HDFS Haga clic para ampliar la imagen Hadoop MapReduce MapReduce es el nÃºcleo de Hadoop. El tÃ©rmino MapReduce en realidad se refiere a dos procesos separados que Hadoop ejecuta. El primer proceso map , el cual toma un conjunto de datos y lo convierte en otro conjunto, donde los elementos individuales son separados en tuplas (pares de llave/valor). El proceso reduce obtiene la salida de map como datos de entrada y combina las tuplas en un conjunto mÃ¡s pequeÃ±o de las mismas. Una fase intermedia es la denominada Shuffle la cual obtiene las tuplas del proceso map y determina que nodo procesarÃ¡ estos datos dirigiendo la salida a una tarea reduce en especÃ­fico. La siguiente figura ejemplifica un flujo de datos en un proceso sencillo de MapReduce. Haga clic para ampliar la imagen Figura 3. Ejemplo de MapReduce Hadoop Common Hadoop Common Components son un conjunto de librerÃ­as que soportan varios subproyectos de Hadoop. AdemÃ¡s de estos tres componentes principales de Hadoop, existen otros proyectos relacionados los cuales son definidos a continuaciÃ³n: Avro Es un proyecto de Apache que provee servicios de serializaciÃ³n. Cuando se guardan datos en un archivo, el esquema que define ese archivo es guardado dentro del mismo; de este modo es mÃ¡s sencillo para cualquier aplicaciÃ³n leerlo posteriormente puesto que el esquema esta definido dentro del archivo. Cassandra Cassandra es una base de datos no relacional distribuida y basada en un modelo de almacenamiento de <clave-valor>, desarrollada en Java. Permite grandes volÃºmenes de datos en forma distribuida. Twitter es una de las empresas que utiliza Cassandra dentro de su plataforma. Chukwa DiseÃ±ado para la colecciÃ³n y anÃ¡lisis a gran escala de "logs". Incluye un toolkit para desplegar los resultados del anÃ¡lisis y monitoreo. Flume Tal como su nombre lo indica, su tarea principal es dirigir los datos de una fuente hacia alguna otra localidad, en este caso hacia el ambiente de Hadoop. Existen tres entidades principales: sources, decorators y sinks. Un source es bÃ¡sicamente cualquier fuente de datos, sink es el destino de una operaciÃ³n en especÃ­fico y un decorator es una operaciÃ³n dentro del flujo de datos que transforma esa informaciÃ³n de alguna manera, como por ejemplo comprimir o descomprimir los datos o alguna otra operaciÃ³n en particular sobre los mismos. HBase Es una base de datos columnar (column-oriented database) que se ejecuta en HDFS. HBase no soporta SQL, de hecho, HBase no es una base de datos relacional. Cada tabla contiene filas y columnas como una base de datos relacional. HBase permite que muchos atributos sean agrupados llamÃ¡ndolos familias de columnas, de tal manera que los elementos de una familia de columnas son almacenados en un solo conjunto. Eso es distinto a las bases de datos relacionales orientadas a filas, donde todas las columnas de una fila dada son almacenadas en conjunto. Facebook utiliza HBase en su plataforma desde Noviembre del 2010. Hive Es una infraestructura de data warehouse que facilita administrar grandes conjuntos de datos que se encuentran almacenados en un ambiente distribuido. Hive tiene definido un lenguaje similar a SQL llamado Hive Query Language(HQL), estas sentencias HQL son separadas por un servicio de Hive y son enviadas a procesos MapReduce ejecutados en el cluster de Hadoop. El siguiente es un ejemplo en HQL para crear una tabla, cargar datos y obtener informaciÃ³n de la tabla utilizando Hive: 1 2 3 4 5 6 7 CREATE TABLE Tweets (from_user STRING, userid BIGINT, tweettext STRING, retweets INT) COMMENT 'This is the Twitter feed table' STORED AS SEQUENCEFILE; LOAD DATA INPATH 'hdfs://node/tweetdata' INTO TABLE TWEETS; SELECT from_user, SUM(retweets) FROM TWEETS GROUP BY from_user; Jaql Fue donado por IBM a la comunidad de software libre. Query Language for Javascript Object Notation (JSON) es un lenguaje funcional y declarativo que permite la explotaciÃ³n de datos en formato JSON diseÃ±ado para procesar grandes volÃºmenes de informaciÃ³n. Para explotar el paralelismo, Jaql reescribe los queries de alto nivel (cuando es necesario) en queries de "bajo nivel" para distribuirlos como procesos MapReduce. Internamente el motor de Jaql transforma el query en procesos map y reduce para reducir el tiempo de desarrollo asociado en analizar los datos en Hadoop. Jaql posee de una infraestructura flexible para administrar y analizar datos semiestructurados como XML, archivos CSV, archivos planos, datos relacionales, etc. Lucene Es un proyecto de Apache bastante popular para realizar bÃºsquedas sobre textos. Lucene provee de librerÃ­as para indexaciÃ³n y bÃºsqueda de texto. Ha sido principalmente utilizado en la implementaciÃ³n de motores de bÃºsqueda (aunque hay que considerar que no tiene funciones de "crawling" ni anÃ¡lisis de documentos HTML ya incorporadas). El concepto a nivel de arquitectura de Lucene es simple, bÃ¡sicamente los documentos ( document ) son dividos en campos de texto ( fields ) y se genera un Ã­ndice sobre estos campos de texto. La indexaciÃ³n es el componente clave de Lucene, lo que le permite realizar bÃºsquedas rÃ¡pidamente independientemente del formato del archivo, ya sean PDFs, documentos HTML, etc. Oozie Como pudo haber notado, existen varios procesos que son ejecutados en distintos momentos los cuales necesitan ser orquestados para satisfacer las necesidades de tan complejo anÃ¡lisis de informaciÃ³n. Oozie es un proyecto de cÃ³digo abierto que simplifica los flujos de trabajo y la coordinaciÃ³n entre cada uno de los procesos. Permite que el usuario pueda definir acciones y las dependencias entre dichas acciones. Un flujo de trabajo en Oozie es definido mediante un grafo acÃ­clico llamado Directed Acyclical Graph (DAG), y es acÃ­clico puesto que no permite ciclos en el grafo; es decir, solo hay un punto de entrada y de salida y todas las tareas y dependencias parten del punto inicial al punto final sin puntos de retorno. Un ejemplo de un flujo de trabajo en Oozie se representa de la siguiente manera: Figura 4. Flujo de trabajo en Oozie Haga clic para ampliar la imagen Pig Inicialmente desarrollado por Yahoo para permitir a los usuarios de Hadoop enfocarse mÃ¡s en analizar todos los conjuntos de datos y dedicar menos tiempo en construir los programas MapReduce. Tal como su nombre lo indica al igual que cualquier cerdo que come cualquier cosa, el lenguaje PigLatin fue diseÃ±ado para manejar cualquier tipo de dato y Pig es el ambiente de ejecuciÃ³n donde estos programas son ejecutados, de manera muy similar a la relaciÃ³n entre la mÃ¡quina virtual de Java (JVM) y una aplicaciÃ³n Java. ZooKeeper ZooKeeper es otro proyecto de cÃ³digo abierto de Apache que provee de una infraestructura centralizada y de servicios que pueden ser utilizados por aplicaciones para asegurarse de que los procesos a travÃ©s de un cluster sean serializados o sincronizados. Internamente en ZooKeeper una aplicaciÃ³n puede crear un archivo que se persiste en memoria en los servidores ZooKeeper llamado znode. Este archivo znode puede ser actualizado por cualquier nodo en el cluster, y cualquier nodo puede registrar que sea informado de los cambios ocurridos en ese znode ; es decir, un servidor puede ser configurado para "vigilar" un znode en particular. De este modo, las aplicaciones pueden sincronizar sus procesos a travÃ©s de un cluster distribuido actualizando su estatus en cada znode , el cual informarÃ¡ al resto del cluster sobre el estatus correspondiente de algÃºn nodo en especÃ­fico. Como podrÃ¡ observar, mÃ¡s allÃ¡ de Hadoop, una plataforma de Big Data consiste de todo un ecosistema de proyectos que en conjunto permiten simplificar, administrar, coordinar y analizar grandes volÃºmenes de informaciÃ³n. 5. Big Data y el campo de investigaciÃ³n Los cientÃ­ficos e investigadores han analizado datos desde ya hace mucho tiempo, lo que ahora representa el gran reto es la escala en la que estos son generados. Esta explosiÃ³n de "grandes datos" estÃ¡ transformando la manera en que se conduce una investigaciÃ³n adquiriendo habilidades en el uso de Big Data para resolver problemas complejos relacionados con el descubrimiento cientÃ­fico, investigaciÃ³n ambiental y biomÃ©dica, educaciÃ³n, salud, seguridad nacional, entre otros. De entre los proyectos que se pueden mencionar donde se ha llevado a cabo el uso de una soluciÃ³n de Big Data se encuentran: El Language, Interaction and Computation Laboratory (CLIC) en conjunto con la Universidad de Trento en Italia, son un grupo de investigadores cuyo interÃ©s es el estudio de la comunicaciÃ³n verbal y no verbal tanto con mÃ©todos computacionales como cognitivos. Lineberger Comprehensive Cancer Center - Bioinformatics Group utiliza Hadoop y HBase para analizar datos producidos por los investigadores de The Cancer Genome Atlas(TCGA) para soportar las investigaciones relacionadas con el cÃ¡ncer. El PSG College of Technology, India , analiza mÃºltiples secuencias de proteÃ­nas para determinar los enlaces evolutivos y predecir estructuras moleculares. La naturaleza del algoritmo y el paralelismo computacional de Hadoop mejora la velocidad y exactitud de estas secuencias. La Universidad Distrital Francisco Jose de Caldas utiliza Hadoop para apoyar su proyecto de investigaciÃ³n relacionado con el sistema de inteligencia territorial de la ciudad de BogotÃ¡. La Universidad de Maryland es una de las seis universidades que colaboran en la iniciativa acadÃ©mica de cÃ³mputo en la nube de IBM/Google. Sus investigaciones incluyen proyectos en la lingÃ¼istica computacional (machine translation), modelado del lenguaje, bioinformÃ¡tica, anÃ¡lisis de correo electrÃ³nico y procesamiento de imÃ¡genes. Para mÃ¡s referencias en el uso de Hadoop puede dirigirse a : http://wiki.apache.org/hadoop/PoweredBy El Instituto de TecnologÃ­a de la Universidad de Ontario (UOIT) junto con el Hospital de Toronto utilizan una plataforma de big data para anÃ¡lisis en tiempo real de IBM ( IBM InfoSphere Streams ), la cual permite monitorear bebÃ©s prematuros en las salas de neonatologÃ­a para determinar cualquier cambio en la presiÃ³n arterial, temperatura, alteraciones en los registros del electrocardiograma y   electroencefalograma, etc., y asÃ­ detectar hasta 24 horas antes aquellas condiciones que puedan ser una amenaza en la vida de los reciÃ©n nacidos. Los laboratorios Pacific Northwest National Labs (PNNL) utilizan de igual manera IBM InfoSphere Streams para analizar eventos de medidores de su red elÃ©ctrica y en tiempo real verificar aquellas excepciones o fallas en los componentes de la red, logrando comunicar casi de manera inmediata a los consumidores sobre el problema para ayudarlos en administrar su consumo de energÃ­a elÃ©ctrica.[3] La esclerosis mÃºltiple es una enfermedad del sistema nervioso que afecta al cerebro y la mÃ©dula espinal. La comunidad de investigaciÃ³n biomÃ©dica y la Universidad del Estado de Nueva York (SUNY) estÃ¡n aplicando anÃ¡lisis con big data para contribuir en la progresiÃ³n de la investigaciÃ³n, diagnÃ³stico, tratamiento, y quizÃ¡s hasta la posible cura de la esclerosis mÃºltiple.[4] Con la capacidad de generar toda esta informaciÃ³n valiosa de diferentes sistemas, las empresas y los gobiernos estÃ¡n lidiando con el problema de analizar los datos para dos propÃ³sitos importantes: ser capaces de detectar y responder a los acontecimientos actuales de una manera oportuna, y para poder utilizar las predicciones del aprendizaje histÃ³rico. Esta situaciÃ³n requiere del anÃ¡lisis tanto de datos en movimiento (datos actuales) como de datos en reposo (datos histÃ³ricos), que son representados a diferentes y enormes volÃºmenes, variedades y velocidades. 6. Conclusiones La naturaleza de la informaciÃ³n hoy es diferente a la informaciÃ³n en el pasado. Debido a la
                abundacia de sensores, micrÃ³fonos, cÃ¡maras, escÃ¡neres mÃ©dicos, imÃ¡genes, etc. en
                nuestras vidas, los datos generados a partir de estos elementos serÃ¡n dentro de poco
                el segmento mÃ¡s grande de toda la informaciÃ³n disponible. El uso de Big Data ha ayudado a los investigadores a descubrir cosas que les podrÃ­an haber tomado aÃ±os en descubrir por si mismos sin el uso de estas herramientas, debido a la velocidad del anÃ¡lisis, es posible que el analista de datos pueda cambiar sus ideas basÃ¡ndose en el resultado obtenido y retrabajar el procedimiento una y otra vez hasta encontrar el verdadero valor al que se estÃ¡ tratando de llegar. Como se pudo notar en el presente artÃ­culo, implementar una soluciÃ³n alrededor de
                                Big Data implica de la integraciÃ³n de diversos componentes y
                                proyectos que en conjunto forman el ecosistema necesario para
                                analizar grandes cantidades de datos. Sin una plataforma de Big Data se necesitarÃ­a que desarrollar adicionalmente cÃ³digo que permita administrar cada uno de esos componentes como por ejemplo: manejo de eventos, conectividad, alta disponibilidad, seguridad, optimizaciÃ³n y desempeÃ±o, depuraciÃ³n, monitoreo, administraciÃ³n de las aplicaciones, SQL y scripts personalizados. IBM cuenta con una plataforma de Big Data basada en dos productos principales: IBM InfoSphere BigInsightsâ„¢ e IBM InfoSphere Streamsâ„¢, ademÃ¡s de su reciente adquisiciÃ³n Vivisimo, los cuales estÃ¡n diseÃ±ados para resolver este tipo de problemas. Estas herramientas estÃ¡n construidas para ser ejecutadas en sistemas distribuidos a gran escala diseÃ±ados para tratar con grandes volÃºmenes de informaciÃ³n, analizando tanto datos estructurados como no estructurados. Dentro de la plataforma de IBM existen mÃ¡s de 100 aplicaciones de ejemplo recolectadas del trabajo que se ha realizado internamente en la empresa para casos de uso e industrias especÃ­ficas. Estos aplicativos estÃ¡n implementados dentro de la soluciÃ³n de manera que las organizaciones puedan dedicar su tiempo a analizar y no a implementar. 7. Referencias Cisco, Internet serÃ¡ cuatro veces mÃ¡s grande en 2016 , ArtÃ­culo Web http://www.cisco.com/web/ES/about/press/2012/2012-05-30-internet-sera-cuatro-veces-mas-grande-en-2016--informe-vini-de-cisco.html Soares Sunil, Not Your Type? Big Data Matchmaker On Five Data Types You Need To Explore Today , ArtÃ­culo Web http://www.dataversity.net/not-your-type-big-data-matchmaker-on-five-data-types-you-need-to-explore-today/ Clegg Dai, Big Data: The Data Velocity Discussion , ArtÃ­culo Web http://thinking.netezza.com/blog/big-data-data-velocity-discussion Kobielus James, Big Data Analytics Helps Researchers Drill Deeper into Multiple Sclerosis , ArtÃ­culo Web http://thinking.netezza.com/blog/big-data-analytics-helps-researchers-drill-deeper-multiple-sclerosis Aprenda mÃ¡s acerca de Apache Hadoop en http://hadoop.apache.org/ Zikopolous Paul, Deroos Dirk, Deutsch Tom, Lapis George, Understanding Big Data: Analytics for Enterprise Class Hadoop and Streaming Data , McGraw-Hill, 2012 Foster Kevin, Nathan Senthil, Rajan Deepak, Ballard Chuck, IBM InfoSphere Streams: Assembling Continuous Insight in the Information Revolution , IBM RedBooks, 2011    Recursos para Descargar PDF de este contenido       Comentarios   Inicie SesiÃ³n o RegÃ­strese para agregar comentarios.      Reciba notificaciones de los comentarios     Postear MÃ¡s recientes MÃ¡s antiguos MÃ¡s populares MÃ¡s recientes MÃ¡s recientes MÃ¡s antiguos MÃ¡s populares 29-04-2018 itmr2018 muy bueno la introduccion Responder Â· 0 Â· Reportar abusos 16-07-2017 canariony Muy buen artÃ­culo. Generalmente es muy complicado encontrar informaciÃ³n tan completa, gracias por la aportaciÃ³n. Actualmente estoy realizando cursos en la academia www.soydata.net y estoy bastante contento con los profesores que tienen en el Ã¡rea de big data.

Un saludo Responder Â· 0 Â· Reportar abusos 27-05-2016 franciscojaviercervigonruckauer Los datos se han convertido en el nuevo petrÃ³leo de la economÃ­a. El concepto de "datificaciÃ³n", relacionado con el paradigma Big Data, consiste en convertir cualquier acciÃ³n o evento susceptible de ser medido en datos digitales http://8cervigon.blogspot.com Responder Â· 0 Â· Reportar abusos 25-01-2016 LauraMartÃ­nez Muchas gracias, excelente artÃ­culo!

Sin duda, los grandes volÃºmenes de datos suponen un reto para las empresas. Cada vez mÃ¡s las empresas valoraran mÃ¡s poder captar toda esta <span style="color: #000000;"><a style="text-decoration: none; color: #000000;" href=" http://www.lantares.com/blog/ayer-hoy-y-manana-de-la-inteligencia-de-negocio ">inteligencia empresarial</a> para una buena toma de decisiones. Responder Â· 0 Â· Reportar abusos 16-05-2015 wilmarrengifo WILMAR RENGIFO CI:20952182
â€œBig dataâ€ son activos de informaciÃ³n caracterizados por su alto volumen, velocidad y variedad, que demandan soluciones innovadoras y eficientes de procesado para la mejora del conocimiento y toma de decisiones en las organizaciones. El objetivo fundamental del big data es dotar de una infraestructura tecnolÃ³gica a las empresas y organizaciones con la finalidad de poder almacenar, tratar y analizar de manera econÃ³mica, rÃ¡pida y flexible la gran cantidad de datos que se generan diariamente, para ello es necesario el desarrollo y la implantaciÃ³n tanto de hardware como de software especÃ­ficos que gestionen esta explosiÃ³n de datos con el objetivo de extraer valor para obtener informaciÃ³n Ãºtil para nuestros objetivos o negocios.Big data puede aplicarse tanto en empresas multinacionales como Google, Facebook o Coca-cola asÃ­ como en pequeÃ±as empresas, EJEMPLO:el caso de una pequeÃ±a empresa tras aplicar big data a un perfil determinado de usuarios de una red social. Responder Â· 0 Â· Reportar abusos 25-02-2015 rbarran Gracias por sus comentarios, espero que la informaciÃ³n haya sido Ãºtil para todos ustedes y seguiremos compartiendo mÃ¡s artÃ­culos en innovaciÃ³n tecnolÃ³gica.
@Marcelodagos: Porfavor bÃºscame a travÃ©s de la red de developerworks o a travÃ©s de mi correo rbarran@mx1.ibm.com para platicar mÃ¡s al respecto.
@acuevasrivero: Por supuesto!! Sin duda ingresa a bigdatauniversity.com y encontrarÃ¡s tutoriales y material de aprendizaje.
Saludos a todos!!! Responder Â· 0 Â· Reportar abusos 13-11-2014 Marcelodagos Excelente este post. Soy el Director de Gestion del Conocimiento, Bioetica e Investigacion de la OrganizaciÃ³n Panamericana de la Salud y estamos trabajando con BigData y Salud Publica y quisiera saber si existe algÃºn proyecto o interÃ©s de IBM en conversar con nosotros y explorar proyectos que puedan beneficiar a la Salud Publica en todos los paÃ­ses de America.

Muchas gracias,
Marcelo

Twitter personal @marcelodagos Responder Â· 0 Â· Reportar abusos 15-08-2014 jsavino muy buen artÃ­culo. Responder Â· 0 Â· Reportar abusos 11-08-2014 acuevasrivero Muy buen artÃ­culo, conocen alguna iniciativa Big Data es que se pueda participar gratuitamente con el fin aportar y aprender del tema?

Gracias Responder Â· 0 Â· Reportar abusos 03-07-2013 Eduardo.C.Moya "Excelente post, deja claro el concepto, como surge y muestra herramientas explicadas al punto, me gusto mucho, espero que sigan estos post tan interesantes, yo soy estudiante de ultimo aÃ±o de IngenierÃ­a en Telematica y me gustarÃ­a recibir toda la informacion que ustedes puedan ofrecer, actualizaciones, nuevos esquemas, herramientas todo jeje.\n \nMuchas gracias, un saludo desde Costa Rica... Responder Â· 0 Â· Reportar abusos 29-10-2012 aledesmac Gracias por su comentario Arturo. Nosotros no manejamos manuales impresos sobre los temas de dW, sin embargo, contantemente publicamos informaciÃ³n relativa a Big Data en espaÃ±ol, por lo que lo invitamos a seguirnos en Twitter @dWEspanol y enterarse asÃ­ cuando hay mÃ¡s contenido relacionado, o bien, a visitar este recurso en inglÃ©s: http:\/\/www.redbooks.ibm.com\/abstracts\/redp4877.html?Open Responder Â· 0 Â· Reportar abusos 27-10-2012 pantalla10 Me gustaria recibir un manual de Big Data para aprenderlo.\nArturo Rojas\nIngeniero de Sistemas\nDB2\/Java Developer\nCalle 25C No. 33-07, Piso 3.\nBogota D.C., Colombia Responder Â· 0 Â· Reportar abusos No hay comentarios en este artÃ­culo       static.content.url=http://www.ibm.com/developerworks/js/artrating/ SITE_ID=90 Zone=Information mgmt ArticleID=821203 ArticleTitle=Â¿QuÃ© es Big Data? publish-date=06182012 url=https://www.ibm.com/developerworks/ssa/local/im/que-es-big-data/index.html                     developerWorks  Acerca de  Informar abusos  Aviso de tÃ©rminos legales de terceros    SÃ­guenos                Ãšnete  Universidad  Startups (InglÃ©s)  Business Partners (InglÃ©s)    Seleccione un idioma  English  ä¸­æ–‡  æ—¥æœ¬èªž  Ð ÑƒÑÑÐºÐ¸Ð¹  PortuguÃªs (Brasil)  EspaÃ±ol  í•œê¸€         Descargas        BoletÃ­n (InglÃ©s)        Tutoriales & entrenamientos             Contacto  Privacidad  Condiciones de uso  Accesibilidad  Comentarios  Preferencias de cookies    Seleccione un paÃ­s/regiÃ³n Argentina - Spanish Afghanistan - English Algeria - French Angola - Portuguese Anguilla - English Antigua and Barbuda - English Aruba - English Australia - English Austria - German Bahamas - English Bahrain - English Bangladesh - English Barbados - English Belgium/Luxembourg - Dutch Belgium/Luxembourg - English Belgium/Luxembourg - French Bermuda - English Bolivia - Spanish Botswana - English Brazil - Portuguese Brunei Darussalam - English Bulgaria - Bulgarian Burkina Faso - French Cambodia - English Cameroon - English Cameroon - French Canada - English Canada - French Cayman Islands - English Chad - French Chile - Spanish China - Chinese (Simplified) Colombia - Spanish Congo - French Congo, The Democratic Republic of the - French Costa Rica - Spanish Croatia - Croatian Curacao - English Cyprus - English Czech Republic - Czech Denmark - Danish Dominica - English Ecuador - Spanish Egypt - English Estonia - Estonian Ethiopia - English Finland - Finnish France - French Gabon - French Germany - German Ghana - English Greece - Greek Grenada - English Guyana - English Hong Kong S.A.R. of China - English Hungary - Hungarian India - English Indonesia - English Iraq - English Ireland - English Israel - Hebrew Italy - Italian Ivory Coast - French Jamaica - English Japan - Japanese Jordan - English Kazakhstan - Kazakh Kenya - English Korea, Republic of - Korean Kuwait - English Latvia - Latvian Lebanon - English Libya - English Lithuania - Lithuanian Madagascar - French Malawi - English Malaysia - English Mauritius - English Mauritius - French Mexico - Spanish Montserrat - English Morocco - French Mozambique - Portuguese Namibia - English Nepal - English Netherlands - Dutch New Zealand - English Niger - French Nigeria - English Norway - Norwegian Oman - English Pakistan - English Paraguay - Spanish Peru - Spanish Philippines - English Poland - Polish Portugal - Portuguese Qatar - English Romania - Romanian Russian Federation - Russian Saint Kitts and Nevis - English Saint Lucia - English Saint Vincent and the Grenadines - English Saudi Arabia - English Senegal - French Serbia - Serbian Seychelles - French Sierra Leone - English Singapore - English Slovakia - Slovak Slovenia - Slovenian South Africa - English Spain - Spanish Sri Lanka - English Suriname - English Sweden - Swedish Switzerland - French Switzerland - German Taiwan - Chinese (Traditional) Tanzania, United Republic of - English Thailand - English Trinidad and Tobago - English Tunisia - French Turkey - Turkish Turks and Caicos Islands - English Uganda - English Ukraine - Ukrainian United Arab Emirates - English United Kingdom - English United States - English Uruguay - Spanish Uzbekistan - Uzbek Venezuela - Spanish Vietnam - English Vietnam - Vietnamese Virgin Islands, British - English Yemen - English Zambia - English Zimbabwe - English Argentina - Spanish                    Cerrar Cerrar Cerrar Cerrar Cookie Preferences