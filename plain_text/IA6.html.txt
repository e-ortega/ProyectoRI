Â­    Pasar al contenido principal      .         Secciones + Biomedicina  ComputaciÃ³n  EnergÃ­a  MÃ³vil  Negocios  RobÃ³tica  10 TecnologÃ­as Emergentes  Las 50 Empresas mÃ¡s Inteligentes  OpiniÃ³n  Habla el mercado  Innovadores a Fondo   Actualidad  Innovadores  MÃ¡s + Eventos     Formulario de bÃºsqueda            Menu    Suscribirse Arrow  Buscar   Secciones + Biomedicina ComputaciÃ³n EnergÃ­a MÃ³vil Negocios RobÃ³tica 10 TecnologÃ­as Emergentes Las 50 Empresas mÃ¡s Inteligentes OpiniÃ³n Habla el mercado Innovadores a Fondo Actualidad Innovadores MÃ¡s + Eventos      Escriba las palabras clave.                                                     MÃ³vil   La inteligencia artificial le planta cara a las noticias falsas  1    Uno de los grandes males de la 
sociedad actual son los contenidos engaÃ±osos. Varias iniciativas 
intentan combatirlos con programas automÃ¡ticos que buscan pistas para 
identificarlos o acelerar la labor de los verificadores humanos. Pero 
esta soluciÃ³n no durarÃ¡ mucho tiempo                                        por Jackie Snow | traducido por Teresa Woods  21 Diciembre, 2017                       Tal vez fuera la primera noticia falsa de la historia de internet: 
en 1984, alguien publicÃ³ que la UniÃ³n SoviÃ©tica se unÃ­a a la red. 
Era una broma inofensiva del DÃ­a de los Inocentes que nada tiene que ver con las
 actuales campaÃ±as de desinformaciÃ³n y las creaciÃ³n sin escrÃºpulos 
de noticias falsas diseÃ±adas para obtener beneficios a muy corto plazo 
(ver OFERTA: Manipule a los votantes con noticias falsas por menos de 400.000 euros ). En 2017, los
 contenidos digitales engaÃ±osos y maliciosamente falsos se han vuelto 
tan comunes que las personas nos hemos quedado sin escapatoria ante ellos.  Mientras algunos, como el Partido Popular de EspaÃ±a, intentan 
resolver el problema de las noticias falsas con leyes, otros creen 
que la soluciÃ³n estÃ¡ en las mÃ¡quinas. AdVerif.ai es un nuevo algoritmo de la start-up con el mismo nombre. El software de inteligencia artificial (IA) estÃ¡ diseÃ±ado para detectar historias falsas, desnudos, malware y una serie de otros tipos de contenidos problemÃ¡ticos. AdVerif.ai, que lanzÃ³ una versiÃ³n beta en noviembre, ya estÃ¡ trabajando
 con plataformas de contenidos y redes publicitarias en Estados Unidos y
 Europa que no quieren asociarse con historias falsas o potencialmente 
ofensivas.  SegÃºn el fundador de AdVerif.ai, Or Levi, su empresa ha preferido 
centrarse en un producto para empresas en lugar de en algo dirigido al 
usuario medio. Mientras que los consumidores individuales pueden no 
preocuparse por la veracidad de cada historia que leen (ver Usted es la mejor (y tal vez la Ãºnica) herramienta contra las noticias falsas ), los anunciantes y las plataformas de contenidos pueden salir perdiendo si alojan o publicitar contenidos falsos .
 Y si cambian sus polÃ­ticas podrÃ­an cercenar las fuentes de 
ingresos de las personas que ganan dinero generando noticias falsas. 
"SerÃ­a un gran paso en la lucha contra este tipo de contenidos", afirma 
Levi.  AdVerif.ai escanea los contenidos para detectar indicios de 
que algo no estÃ¡ bien, como titulares que no coinciden con el cuerpo de 
texto, por ejemplo, o demasiadas mayÃºsculas en un tÃ­tulo . 
TambiÃ©n verifica cada historia con su base de datos de miles de 
historias legÃ­timas y falsas, que se actualiza semanalmente. Los 
clientes ven un informe por cada contenido que el sistema analice, con 
puntajes que evalÃºan la probabilidad de que algo sea una noticia falsa, 
incluya cÃ³digo malicioso o contenga cualquier otra cosa que el 
sistema tenga que buscar, como la desnudez. Levi  planea aÃ±adir la 
capacidad de detectar imÃ¡genes manipuladas y ofrecer un complemento para
 navegadores web.  Al probar una versiÃ³n de demostraciÃ³n de AdVerif.ai, su inteligencia artificial reconociÃ³ a la publicaciÃ³n The Onion (equivalente a El Mundo Today ) como sÃ¡tira (algo que ha engaÃ±ado a muchas personas en el pasado). Las historias de Breitbart News fueron clasificadas como "poco fiables, derechistas, polÃ­ticas, tendenciosas", mientras que Cosmopolitan fue considerada "izquierdista". Pudo identificar cuando una cuenta de Twitter usaba un logotipo pero 
los enlaces no estaban asociados con la marca que retrataba. AdVerif.ai 
no solo descubriÃ³ que una historia de Natural News con el titular Las
 pruebas apuntan a que Bitcoin es una guerra psicolÃ³gica diseÃ±ada por la
 Agencia de Seguridad Nacional de EEUU para lanzar una moneda digital 
mundial provenÃ­a de una pÃ¡gina de la lista negra, tambiÃ©n la 
identificÃ³ como una noticia falsa que aparecÃ­a en otras pÃ¡ginas de la 
lista negra sin ninguna referencia por parte de organizaciones de 
noticias legÃ­timas.  Algunas historias dudosas siguen colÃ¡ndose. En una pÃ¡gina llamada Action News 3, una actualizaciÃ³n titulada Â¡Un jugador de la NFL es fotografiado quemando una bandera estadounidense en el vestuario! pasÃ³ la criba del sistema a pesar de que se ha demostrado que estÃ¡ prefabricada . Para ayudarle a aprender sobre la marcha, su lista negra de historias falsas puede ser actualizada manualmente contenido a contenido.  AdVerif.ai no es la Ãºnica start-up que intenta aprovechar la oportunidad de proporcionar un suero de verdad con inteligencia artificial. Las firmas de ciberseguridad en
 particular se han apresurado a aÃ±adir servicios de detecciÃ³n de 
noticias falsas y bots a su repertorio, seÃ±alando cuÃ¡nto se parecen 
muchos de los mÃ©todos al hackeo. Facebook estÃ¡ modificando sus algoritmos para que minimice la difusiÃ³n de las noticias falsas y Google se ha asociado con una pÃ¡gina de verificaciÃ³n de datos ,  hasta el momento con resultados mixtos .
 El Fake News Challenge (DesafÃ­o de Noticias Falsas), una competiciÃ³n 
dirigida por voluntarios de la comunidad de la inteligencia artificial, 
se lanzÃ³ a finales del aÃ±o pasado con el objetivo de fomentar el 
desarrollo de herramientas que puedan ayudar a combatir los informes de 
mala fe.  Uno de sus organizadores y fundador de Joostware, una compaÃ±Ã­a que 
desarrolla sistemas de aprendizaje automÃ¡tico, Delip Rao, dijo que 
detectar noticias falsas tiene tantas facetas que el desafÃ­o va a 
requerir varias fases. La primera es la de "detecciÃ³n del 
posicionamiento", o tomar una historia y averiguar quÃ© tienen que decir 
otras pÃ¡ginas de noticias sobre el tema. Esto permitirÃ­a que los 
verificadores humanos se basen en historias para validar otras historias
 y que pasen menos tiempo revisando historias individuales.  El DesafÃ­o de Noticias Falsas ofreciÃ³ conjuntos de datos 
a los 50 equipos participantes. Talos Intelligence, una divisiÃ³n de
 seguridad cibernÃ©tica de Cisco, ganÃ³ el desafÃ­o con un algoritmo que acertÃ³ en mÃ¡s del 80%, algo que no estÃ¡ del todo a la altura ,
 pero que aun asÃ­ representa un resultado alentador. El prÃ³ximo desafÃ­o 
podrÃ­a abordar imÃ¡genes con texto superpuesto (piense en memes, pero con
 informaciÃ³n falsa), un formato que a menudo es promocionado en redes 
sociales, ya que a los algoritmos su formato resulta mÃ¡s difÃ­cil de 
descifrar y comprender.  Rao afirma: "bÃ¡sicamente, queremos desarrollar las mejores herramientas para que los inspectores de verificaciÃ³n de datos puedan trabajar muy rÃ¡pido , como si estuvieran bajo el efecto de esteroides".  Pero aunque se desarrolle un sistema efectivo para combatir la 
marea de contenidos falsos, es poco probable que ese sea el final de 
esta historia. Los sistemas de inteligencia artificial ya pueden 
crear textos falsos, asÃ­ como imÃ¡genes y vÃ­deos, increÃ­blemente 
convincentes (ver La inteligencia artificial imita y sustituye personas, pero solo en vÃ­deo ). QuizÃ¡s debido a esto, un  estudio  reciente de  Gartner predice que en 2022 la mayorÃ­a de las personas en economÃ­as avanzadas verÃ¡n mÃ¡s noticias falsas que reales .
 El mismo informe descubriÃ³ que incluso antes de que eso ocurra, los 
contenidos falsos excederÃ¡n la capacidad de la inteligencia artificial 
para detectarlos, cambiando la forma en la que confiamos en las 
informaciones digitales (ver La tecnologÃ­a para manipular contenidos amenaza con devolvernos a las noticias del siglo XX ).  AsÃ­ que parece que el trabajo de AdVerif.ai y otros no tendrÃ¡ la
 Ãºltima palabra en la guerra contra los contenidos falsos. MÃ¡s bien serÃ¡
 la primera vuelta de una carrera armamentÃ­stica, en la que los 
creadores de contenidos falsos generarÃ¡n su propia inteligencia 
artificial capaz de superar los sistemas con "buenas intenciones". Como sociedad, es posible que tengamos que replantearnos cÃ³mo obtenemos nuestra informaciÃ³n.            CrÃ©ditos     Selman Design            Su nombre     Comment *               MÃ³vil  QuÃ© significa estar constantemente contectados unos a otros y disponer de inmensas cantidades de informaciÃ³n al instante.         CÃ³mo arreglar la burbuja de filtros que nos encierra en una 'cÃ¡rcel de opiniÃ³n'  La
 tendencia a consumir informaciÃ³n que coincide con aquello en lo que ya 
creemos existÃ­a antes de Twitter y Facebook. AsÃ­ que aunque 
internet no sea 100 % responsable de que la polarizaciÃ³n de la
 sociedad sea cada vez mayor, podrÃ­a convertirse en una herramienta para
 solucionar el problema  Por Adam Piore        Ni siquiera 'blockchain' puede garantizar el voto electrÃ³nico seguro  Varios
 expertos en ciberseguridad critican los riesgos del proyecto 
piloto del estado de Virginia que permitirÃ¡ a sus votantes en el 
extranjero participar en las elecciones a travÃ©s de una 'app' 
conectada a una cadena de bloques. En su opiniÃ³n, el sistema solo 
sustituye unos peligros por otros  Por AnÃ³nimo        La increible RA de Magic Leap sale a la venta sin saber para quÃ© sirve  Tras
 aÃ±os de trabajo y secretismo, los desarrolladores ya puede adquirir el 
Magic Leap One, un casco que mezcla imÃ¡genes digitales con el mundo real
 de forma impresionante. Pero ni sus responsables saben para quÃ© querrÃ¡ 
usarlo la gente ni si decidirÃ¡ comprarlo  Por Rachel Metz          MÃ¡s informaciÃ³n sobre MÃ³vil                     SÃ­guenos  Twitter Facebook RSS                           CompaÃ±Ã­a QuiÃ©nes somos  ContÃ¡ctenos   Legal PolÃ­tica de Privacidad  TÃ©rminos y Condiciones     Copyright Â© MIT Technology Review, 2017-2018.                      Usamos cookies en este sitio para mejorar la experiencia de usuario. Al hacer clic en cualquier enlace de esta pÃ¡gina nos da su consentimiento para utilizar cookies.    De acuerdo  MÃ¡s info   